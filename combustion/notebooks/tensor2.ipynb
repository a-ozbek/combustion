{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    \"\"\"\n",
    "    Tensor\n",
    "    \"\"\"\n",
    "    def __init__(self, numpy_array, name=None):\n",
    "        if not isinstance(numpy_array, np.ndarray):\n",
    "            raise ValueError(\"Must be initialized with a Numpy array\")\n",
    "        self.value = numpy_array\n",
    "        self.name = str(name)\n",
    "        self.previous_tensors = None\n",
    "        self.operation = None  # type of operation done to create this tensor.\n",
    "        self.grad = None\n",
    "        self.grads = list()\n",
    "        \n",
    "    def backward(self):\n",
    "        self._compute_grads(self)\n",
    "        \n",
    "    def get_grad(self):\n",
    "        return sum(self.grads)\n",
    "    \n",
    "    def _compute_grads(self, tensor):\n",
    "        if tensor.name == 't5':\n",
    "            print('grad', str(tensor.grad))\n",
    "        \n",
    "        if tensor.grad is None:\n",
    "            tensor.grad = np.full(self.value.shape, 1)\n",
    "        \n",
    "        if tensor.previous_tensors is None:\n",
    "            return\n",
    "        else:\n",
    "            t1, t2 = tensor.previous_tensors\n",
    "            if t1.grad is None:\n",
    "                t1.grad = 0\n",
    "            if t2.grad is None:\n",
    "                t2.grad = 0\n",
    "            \n",
    "            if tensor.operation == 'add':\n",
    "                t1.grad = np.copy(tensor.grad)\n",
    "                t2.grad = np.copy(tensor.grad)\n",
    "                t1.grads.append(np.copy(t1.grad))\n",
    "                t2.grads.append(np.copy(t2.grad))\n",
    "            elif tensor.operation == 'mul':\n",
    "                t1.grad = np.copy(tensor.grad * t2.value)\n",
    "                t2.grad = np.copy(tensor.grad * t1.value)\n",
    "                t1.grads.append(np.copy(t1.grad))\n",
    "                t2.grads.append(np.copy(t2.grad))\n",
    "            else:\n",
    "                raise ValueError(\"Invalid operation\")\n",
    "#             tensor.grad = None  # remove for saving memory\n",
    "            self._compute_grads(t1)\n",
    "            self._compute_grads(t2)\n",
    "        \n",
    "    @classmethod\n",
    "    def _accumulate_grads(cls, tensor):\n",
    "        q = list()\n",
    "        q.append(tensor)\n",
    "        \n",
    "    \n",
    "    def _add_tensor(self, other):\n",
    "        \"\"\"\n",
    "        Tensor addition (core)\n",
    "        \"\"\"\n",
    "        if isinstance(other, Tensor):\n",
    "            # check shapes\n",
    "            if not self.value.shape == other.value.shape:\n",
    "                raise ValueError(\"Tensors must have the same shape. shape1: {}, shape2: {}\".\\\n",
    "                                     format(str(self.value.shape), str(other.value.shape)))\n",
    "            operation_result = self.value + other.value\n",
    "            new_tensor = Tensor(operation_result)\n",
    "            new_tensor.operation = 'add'\n",
    "            new_tensor.previous_tensors = [self, other]\n",
    "            return new_tensor\n",
    "        else:\n",
    "            raise ValueError(\"Operands must be of `Tensor` type.\")\n",
    "    \n",
    "    def _mul_tensor(self, other):\n",
    "        \"\"\"\n",
    "        Tensor multiplication (core)\n",
    "        \"\"\"\n",
    "        if isinstance(other, Tensor):\n",
    "            # check shapes\n",
    "            if not self.value.shape == other.value.shape:\n",
    "                raise ValueError(\"Tensors must have the same shape. shape1: {}, shape2: {}\".\\\n",
    "                                     format(str(self.value.shape), str(other.value.shape)))\n",
    "            operation_result = self.value * other.value\n",
    "            new_tensor = Tensor(operation_result)\n",
    "            new_tensor.operation = 'mul'\n",
    "            new_tensor.previous_tensors = [self, other]\n",
    "            return new_tensor\n",
    "        else:\n",
    "            raise ValueError(\"Operands must be of `Tensor` type.\")\n",
    "            \n",
    "    def _convert_other_to_tensor(self, other):\n",
    "        \"\"\"\n",
    "        Convert 'other' to Tensor with proper shape for \n",
    "        proper operation.\n",
    "        \"\"\"\n",
    "        # convert other to Tensor\n",
    "        if isinstance(other, int) or isinstance(other, float):\n",
    "            t = Tensor(np.full(self.value.shape, other))\n",
    "        elif isinstance(other, np.ndarray):\n",
    "            other = np.broadcast_to(other, self.value.shape)\n",
    "            t = Tensor(other)\n",
    "        elif isinstance(other, Tensor):\n",
    "            t = other  # no need to do anything\n",
    "        else:\n",
    "            raise ValueError(\"Invalid type\")\n",
    "        return t\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        print('add is called')\n",
    "        # convert other to tensor\n",
    "        t = self._convert_other_to_tensor(other)\n",
    "        # do tensor addition\n",
    "        return self._add_tensor(t)\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        print('radd is called')\n",
    "        return self.__add__(other)\n",
    "            \n",
    "    def __mul__(self, other):\n",
    "        print('mul is called')\n",
    "        # convert other to tensor\n",
    "        t = self._convert_other_to_tensor(other)\n",
    "        # do tensor multiplication\n",
    "        return self._mul_tensor(t)\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        print('rmul is called')\n",
    "        return self.__mul__(other)\n",
    "        \n",
    "    def __sub__(self, other):\n",
    "        # convert other to tensor\n",
    "        t = self._convert_other_to_tensor(other * (-1))\n",
    "        # do tensor addition\n",
    "        return self._add_tensor(t)\n",
    "    \n",
    "    def __str__(self):\n",
    "        r = self.value.__repr__()\n",
    "        r = r.replace('array', 'Tensor')\n",
    "        if self.name:\n",
    "            r = self.name + ', ' + r\n",
    "        return r\n",
    "    \n",
    "    def __repr__(self):\n",
    "        r = self.value.__repr__()\n",
    "        r = r.replace('array', 'Tensor')\n",
    "        if self.name:\n",
    "            r = self.name + ', ' + r\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.random.rand(2, 3)\n",
    "arr2 = np.random.rand(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: None, Tensor([[0.33660213, 0.81649001, 0.95869224],\n",
      "       [0.60528311, 0.90428262, 0.8819401 ]])\n",
      "t2: None, Tensor([[0.03965075, 0.07126047, 0.85544028],\n",
      "       [0.71360469, 0.9093446 , 0.26482009]])\n"
     ]
    }
   ],
   "source": [
    "t1 = Tensor(arr1)\n",
    "t2 = Tensor(arr2)\n",
    "print('t1:', t1)\n",
    "print('t2:', t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add is called\n",
      "mul is called\n",
      "add is called\n"
     ]
    }
   ],
   "source": [
    "t1.name = 't1'\n",
    "t5 = t1 + t1\n",
    "t5.name = 't5'\n",
    "t6 = t5 * 3 + t5 \n",
    "t6.name = 't6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad [[3 3 3]\n",
      " [3 3 3]]\n",
      "grad [[3 3 3]\n",
      " [3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "t6.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 12, 12],\n",
       "       [12, 12, 12]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.get_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[3 3 3]\n",
      " [3 3 3]]\n",
      "[[3 3 3]\n",
      " [3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "print(len(t5.grads))\n",
    "for _ in t5.grads:\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[3, 3, 3],\n",
       "        [3, 3, 3]]), array([[3, 3, 3],\n",
       "        [3, 3, 3]]), array([[3, 3, 3],\n",
       "        [3, 3, 3]]), array([[3, 3, 3],\n",
       "        [3, 3, 3]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5.previous_tensors[0].grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[3 3 3]\n",
      " [3 3 3]]\n",
      "[[3 3 3]\n",
      " [3 3 3]]\n",
      "[[3 3 3]\n",
      " [3 3 3]]\n",
      "[[3 3 3]\n",
      " [3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "print(len(t1.grads))\n",
    "for _ in t1.grads:\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[1 1 1]\n",
      " [1 1 1]]\n",
      "[[3 3 3]\n",
      " [3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "print(len(t5.grads))\n",
    "for _ in t5.grads:\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[[1 1 1]\n",
      " [1 1 1]]\n",
      "[[1 1 1]\n",
      " [1 1 1]]\n",
      "[[3 3 3]\n",
      " [3 3 3]]\n",
      "[[3 3 3]\n",
      " [3 3 3]]\n",
      "[[3 3 3]\n",
      " [3 3 3]]\n",
      "[[9 9 9]\n",
      " [9 9 9]]\n"
     ]
    }
   ],
   "source": [
    "print(len(t1.grads))\n",
    "for _ in t1.grads:\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [1 1 1]]\n",
      "[[3 3 3]\n",
      " [3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "for _ in t5.grads:\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 3],\n",
       "       [3, 3, 3]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = list()\n",
    "tensors_dict = defaultdict(int)\n",
    "q.append(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "while q:\n",
    "    t = q.pop(0)\n",
    "    t1, t2 = t.previous_tensors\n",
    "    tensors_dict[hash(t1)] = tensors_dict[hash(t1)] + t1.grad\n",
    "    tensors_dict[hash(t2)] = tensors_dict[hash(t2)] + t2.grad\n",
    "    \n",
    "    if t1.previous_tensors:\n",
    "        q.append(t1)\n",
    "        \n",
    "    if t2.previous_tensors:\n",
    "        q.append(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286213808\n",
      "[[2 2 2]\n",
      " [2 2 2]]\n",
      "***\n",
      "-9223372036568561927\n",
      "[[2 2 2]\n",
      " [2 2 2]]\n",
      "***\n",
      "286213843\n",
      "[[2 2 2]\n",
      " [2 2 2]]\n",
      "***\n",
      "286213871\n",
      "[[18 18 18]\n",
      " [18 18 18]]\n",
      "***\n",
      "286213689\n",
      "[[1.22730914 0.27408566 0.23691497]\n",
      " [1.05669763 1.73574169 0.59884902]]\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "for k in tensors_dict:\n",
    "    print(k)\n",
    "    print(tensors_dict[k])\n",
    "    print('***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9223372036568819277"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(t6.previous_tensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t10 = (t1 - 2) * (t1 - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t10.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.99519256, -3.70566587, -3.57598042],\n",
       "       [-2.62173808, -2.41002425, -2.09688913]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([[-1.49759628, -1.85283293, -1.78799021],\n",
       "       [-1.31086904, -1.20501212, -1.04844457]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2 * t1) - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([[2.50240372, 2.14716707, 2.21200979],\n",
       "       [2.68913096, 2.79498788, 2.95155543]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'Tensor' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-1cbdcb4558a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'Tensor' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "t10 = (t1 + 2) / (t1 + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "t10.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.52619492, 4.71267724, 5.95470321],\n",
       "       [4.45144276, 4.1928202 , 5.00457934]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.52619492, 4.71267724, 5.95470321],\n",
       "       [4.45144276, 4.1928202 , 5.00457934]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * arr1 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't20' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f70fb7ca7b5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt20\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 't20' is not defined"
     ]
    }
   ],
   "source": [
    "t20.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8264, 0.3591, 0.8097],\n",
       "        [0.5179, 0.3105, 0.6348]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(2, 3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'txt_another'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'some_another'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.replace('txt', 'some')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
